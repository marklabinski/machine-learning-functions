{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling Methods from Scratch\n",
    "\n",
    "Two resampling methods implemented in this notebook:\n",
    "- Train and test split \n",
    "- k-fold cross validation\n",
    "<br>\n",
    "\n",
    "Mark Labinski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train and Test Split\n",
    "\n",
    "#### Important Notes about Train/Test Splitting:\n",
    "- The training set is used to train the model, while the test set is held back and used to evaluate the performance of the model.\n",
    "- The rows assigned to each set are randomly selected to ensure objectivity between training and evaluating a model\n",
    "- If multiple algorithms are compared or multiple configurations of the same algorithm are compared, the same train/test split should be used for consistent comparison.\n",
    "\n",
    "#### Steps:\n",
    "- The first function calculates how many rows the training set will require.\n",
    "- A copy of the original dataset is made.\n",
    "- Random rows are selected and removed from the copied dataset and added to the train dataset until the train set contains the target number of rows.\n",
    "- The rows that remain in the copy of the dataset are then returned as the test dataset.\n",
    "- The randrange() function from the random model is used to generate a random integer in the range between 0 and the size of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: [[2], [9], [8], [3], [5], [6]]\n",
      "Testing Rows: [[1], [4], [7], [10]]\n"
     ]
    }
   ],
   "source": [
    "from random import randrange, seed\n",
    "\n",
    "# Split a dataset into a train and test set\n",
    "def train_test_split(dataset, split=0.60):\n",
    "    train = list()\n",
    "    train_size = split * len(dataset)\n",
    "    dataset_copy = list(dataset)\n",
    "    while len(train) < train_size:\n",
    "        index = randrange(len(dataset_copy))\n",
    "        train.append(dataset_copy.pop(index))\n",
    "    return train, dataset_copy\n",
    "\n",
    "# Test the train_test_split function using a dataset of 10 rows. \n",
    "#    Use seed to fix the random seed before splitting to ensure the exact same \n",
    "#    split of the data is made every time the code is executed\n",
    "\n",
    "seed(1)\n",
    "dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n",
    "train, test = train_test_split(dataset)\n",
    "print('Training Rows: ' + str(train))\n",
    "print('Testing Rows: ' + str(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold Cross Validation\n",
    "\n",
    "#### Important Notes:\n",
    "- A limitation of train_test_split is that it is a noisy estimate of algorithm performance --> k-fold cross validation is more accurate.\n",
    "- Data is split into k group or \"folds\"\n",
    "- The algorithm is trained and evaluated k times and the perfomance is summarized by taking the mean performance score\n",
    "- First, train the algorithm on the k-1 groups of the data nad evaluate it on the kth hold-out group as the test set. Repeat so each of the k groups is given an opportunity to be held out and used as the test set.\n",
    "    - As such, the value of k should be divisible by the number of rows in your training dataset to ensure each of the k groups has the same number of rows.\n",
    "- Choose a value for k that splits the data into groups with enough rows that each group is still representative of the original dataset.\n",
    "    - Good defaults: k=3 for a small dataset, k=10 for large dataset\n",
    "    - To check if fold sizes are representative, calculate summary stats (mean, std dev) and see how much the values differ from the whole dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2], [9]], [[8], [3]], [[5], [6]], [[7], [10]]]\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    " \n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, folds=3):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / folds)\n",
    "    for i in range(folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    " \n",
    "# test cross validation split\n",
    "seed(1)\n",
    "dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n",
    "folds = cross_validation_split(dataset, 4)\n",
    "print(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
